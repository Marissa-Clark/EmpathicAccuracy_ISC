{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our [toolbox](http://neurolearn.readthedocs.io/en/latest/index.html) there's 2 main python classes that can help achieve ISC analysis:  \n",
    "\n",
    "1) Brain_Data, which is a 1d or 2d representation of a nifti file. In the cases of something like an image with 1 value at each voxel (e.g beta map, T1, etc) this will be a single 1d vector of voxel values. In the case of something with more than 1 value at each voxel (e.g. fMRI time-series, concatenated beta-maps from multiple subjects), this will be a 2d vector of observations X  voxels.  \n",
    "\n",
    "    - This class has a bunch of methods on it to do stuff like simple arithmetic operations, to more sophisticated things like regression, extracting a time-series from a mask, etc\n",
    "\n",
    "2) Adjacency, which is a 1d or 2d representation of a distance matrix or several distance matrices. If theres just 1 distance matrix this will be a single 1d vector (i.e. flattened upper triangle if the matrix is symmetrical, or all values stretched out if it isn't). If there is more than 1 distance matrix this will be a 2d vector of observations X flattened matrix values.  \n",
    "\n",
    "    - This class also has a bunch of methods just like Brain_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need 2 things to do an ISC analysis:  \n",
    "\n",
    "1) Nifti file(s) containing ROI masks within which to compute ISC - this can either be a single 4d file that several ROI masks within it, a single 3d file with just 1 ROI mask, a single 3d file within multiple ROIs indicated by different non-overlapping integer value at each voxel  \n",
    "\n",
    "2) 4d Nifti files for all subjects to correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T22:36:28.580216Z",
     "start_time": "2018-06-27T22:36:28.564847Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdclark/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.5\n"
     ]
    }
   ],
   "source": [
    "import nltools\n",
    "from nltools.data import Brain_Data, Adjacency\n",
    "from nltools.mask import expand_mask\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "print(nltools.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/AdditionalStorage/ISC_Analysis\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/Volumes/AdditionalStorage/ISC_Analysis\"\n",
    "\n",
    "\n",
    "# Useful stuff for dealing with the ROI mask(s)\n",
    "\n",
    "\n",
    "\n",
    "# Single ROI mask in 3d file; just load it up\n",
    "mask = Brain_Data(data = folder_path + '/masked_csv/vDMN.nii.gz') # this now a 1d array of voxels containing 1's and 0s\n",
    "\n",
    "# Multiple ROI mask in 3d file (indicated by integer values at each voxel)\n",
    "#mask = Brain_Data('path/to/mask.nii.gz')\n",
    "# Expand it into a 2d array of mask X voxel\n",
    "#mask = expand_mask(mask)\n",
    "\n",
    "# Multiple ROI mask in 4d file; just load it up\n",
    "#mask = Brain_Data('path/to/mask.nii.gz') # this is a 2d array of mask X voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_TRs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aaa58b052b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msubject_timeseres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_subs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_TRs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# initialize an empty matrix thats subjects X timeseries to save the extracted time-series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_TRs' is not defined"
     ]
    }
   ],
   "source": [
    "#Lets say you want to compute the ISC within an ROI (i.e. the pair-wise correlation of subjects average time-series across the entire ROI)\n",
    "#Below assumes you have just a single mask, but you can easily adapt this by adding another loop over ROIs, e.g. for roi in mask: ...\n",
    "\n",
    "video = 6\n",
    "mask_region = \"vDMN\"\n",
    "\n",
    "subjects = [ '145', '157', '168', '184', '200', '214',  '219', '220', '222', '223', '229', '245', '253', '257', '263',  '267', '270', '277']\n",
    "num_subs = len(subjects)\n",
    "\n",
    "subject = os.path.join(folder_path, 'data', 'sub-' + subjects[0], 'func', 'video_' + str(video) + '.nii.gz')\n",
    "num_TRs = Brain_Data(subject).shape()[0]\n",
    "    \n",
    "\n",
    "\n",
    "subject_timeseres = np.zeros((num_subs,num_TRs)) # initialize an empty matrix thats subjects X timeseries to save the extracted time-series \n",
    "\n",
    "for i, subject in enumerate(subjects):\n",
    "    \n",
    "    #try:\n",
    "    \n",
    "    subject_path = os.path.join(folder_path,'data', 'sub-' + subject, 'func', 'video_' + str(video) + '.nii.gz')\n",
    "    print(subject_path)\n",
    "    \n",
    "    # Load in their data\n",
    "    sub_dat = Brain_Data(subject_path)\n",
    "    \n",
    "    # Extract mean time-series from ROI\n",
    "    sub_roi = sub_dat.extract_roi(mask)\n",
    "\n",
    "    data_frame = pd.DataFrame(sub_roi)\n",
    "    output = os.path.join(folder_path, 'masked_csv', mask_region, subject + '_video' + str(video) + 'mask.csv')\n",
    "\n",
    "    data_frame.to_csv(output, header=None)\n",
    "\n",
    "    #except:\n",
    "     #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets say you want to compute the ISC within an ROI (i.e. the pair-wise correlation of subjects average time-series across the entire ROI)\n",
    "# Below assumes you have just a single mask, but you can easily adapt this by adding another loop over ROIs, e.g. for roi in mask: ...\n",
    "\n",
    "mask_region = \"vDMN\"\n",
    "\n",
    "subjects = [ '145', '157', '168', '184', '200', '214',  '219', '220', '222', '223', '229', '245', '253', '257', '263',  '267', '270', '277']\n",
    "subject = os.path.join(folder_path, 'data', 'sub-' + subjects[1], 'func', 'video_' + str(video) + '.nii.gz')\n",
    "num_subs = len(subjects)\n",
    "\n",
    "num_TRs = Brain_Data(subject).shape()[0]\n",
    "\n",
    "subject_timeseres = np.zeros((num_subs,num_TRs)) # initialize an empty matrix thats subjects X timeseries to save the extracted time-series \n",
    "\n",
    "for i, subject in enumerate(subjects):\n",
    "    csv_path = os.path.join(folder_path, 'masked_csv', mask_region,  subject + \"_video\" + str(video) + \"mask.csv\")\n",
    "\n",
    "    try: \n",
    "        # Load in their data\n",
    "        sub_roi = pd.read_csv(csv_path, header=None)\n",
    "        subject_timeseres[i,:] = sub_roi[1] # just grab the numpy array values \n",
    "    except: pass\n",
    "\n",
    "# Now compute pairwise correlations \n",
    "sub_corrs = 1 - pairwise_distances(subject_timeseres,metric='correlation') # I'm subtracting by 1 because pairwise_distance gives you correlation distances (i.e. values from 0-2), this just converts from -1 to 1\n",
    "\n",
    "# Save it as an adjacency matrix\n",
    "sub_ISC = Adjacency(data=sub_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = sub_corrs\n",
    "\n",
    "# Genesampling_rate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "\n",
    "sns.heatmap(corr, vmax=1, center=0,\n",
    "            square=True, mask=mask, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "ax.set_xticklabels(subjects); \n",
    "ax.set_yticklabels(subjects); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#timeseries\n",
    "\n",
    "\n",
    "plotcorrs = pd.DataFrame(subject_timeseres).transpose().reset_index()\n",
    "\n",
    "plotcorrs = (plotcorrs - plotcorrs.mean()) / (plotcorrs.max() - plotcorrs.min())\n",
    "\n",
    "\n",
    "plotcorrs = plotcorrs.loc[:, (plotcorrs != 0).any(axis=0)]\n",
    "\n",
    "\n",
    "x = plotcorrs['index']\n",
    "y = plotcorrs.drop(['index'], axis=1)\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.title(\"Video: \" + str(video))\n",
    "plt.ylabel('Rating (range 1-9)')\n",
    "plt.xlabel('Time (in seconds)')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(x, y, '--', linewidth=3, alpha=.7);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = Brain_Data(folder_path + '/masked_csv/vDMN.nii.gz') # this now a 1d array of voxels containing 1's and 0s\n",
    "\n",
    "mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject = '157'\n",
    "subject_path = os.path.join(folder_path,'data', 'sub-' + subject, 'func', 'video_' + str(video) + '.nii.gz')\n",
    "print(subject_path)\n",
    "# Load in their data\n",
    "sub_dat = Brain_Data(subject_path)\n",
    "sub_dat = sub_dat.scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Brain_Data.scale(sub_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few other pointers:  \n",
    "\n",
    "If you want to do ISC for multiple ROIs you'll probably want to do something like load in a single subject, loop over a `Brain_Data` object containing multiple ROIs, use the `extract` method to grab mean timeseries from each, then save all those to a single csv file for that subject using pandas or numpy. Then after you've done that for each subject just load in their csv files and proceed with correlating them as you want. This probably the fastest way to do it because very few computers can load say 30 subjects full time-series of a few minutes into RAM at once (unless maybe the time-series are very short). So this way just extracts all the ROIs for each subject first then lets you do whatever analyses you want on them. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
